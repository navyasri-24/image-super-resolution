# -*- coding: utf-8 -*-
"""dp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1svaZlYDn3rS85qN_vEVALNbiZQyxTQYS
"""

#importing libraries
import sys
import keras
import cv2
import numpy
import matplotlib
import skimage
from keras.models import Sequential
from keras.layers import Conv2D
from keras.optimizers import Adam
from skimage.metrics import structural_similarity as ssim
from matplotlib import pyplot as plt
import numpy as np
import cv2
import math
import os

#defining image quality matrics functions
def psnr(target, ref):

#assume RGB image

    target_data = target.astype(float)

    ref_data = ref.astype(float)

    diff =ref_data - target_data

    diff =diff.flatten('C')

    rmse= math.sqrt(np.mean(diff** 2.))

    return 20* math.log10(255. / rmse)

#define function for mean squared error (MSE)

def mse(target, ref):

    #the MSE between the two images is the sum of the squared difference between the two images

    err= np.sum((target.astype('float')- ref.astype('float')) ** 2)

    err/= float(target.shape[0]* target.shape[1])


    return err

#define function that combines all three image quality metrics

def compare_images(target, ref):
    scores = []
    scores.append(psnr(target, ref))
    scores.append(mse(target, ref))
    
    # Calculate an appropriate window size
    win_size = min(target.shape[0], target.shape[1]) // 7
    if win_size % 2 == 0:
        win_size += 1

    # Ensure that the window size is odd and within the bounds of the image dimensions
    win_size = min(win_size, min(target.shape[0], target.shape[1]))

    print("Win Size:", win_size)

    try:
        ssim_score = ssim(target, ref, multichannel=True, win_size=win_size)
        scores.append(ssim_score)
    except ValueError as e:
        print("Error computing SSIM:", e)
        scores.append(None)

    return scores



import os
import cv2

def prepare_images(path, factor):
    # Loop through the files in the directory
    for file in os.listdir(path):
        try:
            # Open the file
            img = cv2.imread(os.path.join(path, file))

            # Find old and new image dimensions
            h, w, _ = img.shape
            new_height = int(h / factor)
            new_width = int(w / factor)

            # Resize the image down
            img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_LINEAR)

            # Resize the image up
            img = cv2.resize(img, (w, h), interpolation=cv2.INTER_LINEAR)

            # Save the image
            print('Saving {}'.format(file))
            cv2.imwrite('images/{}'.format(file), img)

        except Exception as e:
            print('ERROR for file - {}: {}'.format(file, e))

prepare_images('source/', 2)

# Testing Quality difference between source and image (degraded)

for file in os.listdir('images/'):

    try:

        # open target and reference images

        target = cv2.imread('images/{}'.format(file))

        ref = cv2.imread('source/{}'.format(file))

        # calculate score

        scores =compare_images (target, ref)

        # print all three scores with new line characters (\n)

        print('{}\nPSNR: {}\nMSE: {}\nSSIM: {}\n'.format(file, scores[0], scores[1], scores[2]))

    except:

        pass

# Defining SRCNN Model
def model():

    #define model type
    SRCNN = Sequential()

    # add model layers

    SRCNN.add(Conv2D(filters=128, kernel_size = (9, 9), kernel_initializer='glorot_uniform',
                     activation='relu', padding='valid', use_bias=True, input_shape=(None, None, 1)))

    SRCNN.add(Conv2D(filters=64, kernel_size = (3, 3), kernel_initializer='glorot_uniform',
                     activation='relu', padding='same', use_bias=True))

    SRCNN.add(Conv2D(filters=1, kernel_size = (5, 5), kernel_initializer='glorot_uniform',
                     activation='linear', padding='valid', use_bias=True))

    #define optimizer

    adam= Adam (learning_rate=0.0003)

    #compile model

    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])

    return SRCNN

#defining srcnn model
srcnn=model()
srcnn.summary()

# Image Processing Functions
def modcrop(img, scale):
    tmpsz = img.shape
    sz = tmpsz[0:2]
    sz = sz - np.mod(sz, scale)
    img = img[0:sz[0], 1:sz[1]]
    return img


def shave(image, border):
    img = image[border: -border, border: -border]
    return img
# define main prediction function

 #Modify the predict function to handle errors
def predict(image_path):
    # load the srcnn model with weights
    srcnn = model()
    srcnn.load_weights('3051crop_weight_200.h5')

    # load the degraded and reference images
    path, file = os.path.split(image_path)
    degraded = cv2.imread(image_path)
    ref = cv2.imread('source/{}'.format(file))

    # Check if image loading was successful
    if degraded is None or ref is None:
        return None, None, None, None

    # preprocess the image with modcrop
    ref = modcrop(ref, 3)
    degraded = modcrop(degraded, 3)

    # convert the image to YCrCb - (srcnn trained on Y channel)
    temp = cv2.cvtColor(degraded, cv2.COLOR_BGR2YCrCb)

    # create image slice and normalize
    Y = numpy.zeros((1, temp.shape[0], temp.shape[1], 1), dtype=float)
    Y[0, :, :, 0] = temp[:, :, 0].astype(float) / 255

    # perform super-resolution with srcnn
    pre = srcnn.predict(Y, batch_size=1)

    # post-process output
    pre *= 255
    pre[pre[:] > 255] = 255
    pre[pre[:] < 0] = 0
    pre = pre.astype(np.uint8)

    # copy Y channel back to image and convert to BGR
    temp = shave(temp, 6)
    temp[:, :, 0] = pre[0, :, :, 0]
    output = cv2.cvtColor(temp, cv2.COLOR_YCrCb2BGR)

    # Check if the output image is empty
    if output is None:
        return None, None, None, None

    # remove border from reference and degraded image
    ref = shave(ref.astype(np.uint8), 6)
    degraded = shave(degraded.astype(np.uint8), 6)

    # calculate image quality scores
    scores = compare_images(output, ref)

    # return images and scores
    return ref, degraded, output, scores



# print all scores for all images
output_dir='output'
os.makedirs(output_dir, exist_ok=True)

for file in os.listdir('images'):
    # perform super-resolution
    try:
        ref, degraded, output = predict('images/huhu.jpeg'.format(file))
    except:
        continue

    # display images as subplots
    fig, axs = plt.subplots(1, 3, figsize=(20, 8))
    axs[0].imshow(cv2.cvtColor(ref, cv2.COLOR_BGR2RGB))
    axs[0].set_title('Original')
    axs[1].imshow(cv2.cvtColor(degraded, cv2.COLOR_BGR2RGB))
    axs[1].set_title('Degraded')
    axs[2].imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))
    axs[2].set_title('SRCNN')

    # remove the x and y ticks
    for ax in axs:
        ax.set_xticks([])
        ax.set_yticks([])
    output_file=os.path.join(output_dir, '{}.png'.format(os.path.splitext(file)[0]))
    print('Saving {}'.format(output_file))
    fig.savefig(output_file)
    plt.close()
